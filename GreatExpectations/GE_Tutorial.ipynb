{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94093303-31af-464f-8014-1faee1f0e1c7",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "- This notebook follows the documentation of the \"Great Expectations\" package using Pandas Dataframes.\n",
    "- The original document is posted at https://docs.greatexpectations.io/docs/core/connect_to_data/dataframes\n",
    "- The required Python packages are installed on this server. (Make sure to use the \"Conda Python 3.12\" kernel)\n",
    "- Datafiles are in `/data/public/tutorials/ge_tutorials`\n",
    "\n",
    "**Please, note:** The code in this notebook is taken from the code snippets in the tutorial. You need to make edits to make it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a3d4f2b-3cac-45d9-937d-ca0c709bdf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import great_expectations as gx\n",
    "print(gx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0d0bf-4991-4da2-bb81-3dd929cb38ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9be21171-6731-49f5-bed4-05a90850dd4e",
   "metadata": {},
   "source": [
    "# Connect to dataframe data\n",
    "Reference: https://docs.greatexpectations.io/docs/core/connect_to_data/dataframes/\n",
    "\n",
    "A dataframe is a set of data that resides in-memory and is represented in your code by a variable to which it is assigned. To connect to this in-memory data you will define a Data Source based on the type of dataframe you are connecting to, a Data Asset that connects to the dataframe in question, and a Batch Definition that will return all of the records in the dataframe as a single Batch of data.\n",
    "\n",
    "## Create a Data Source\n",
    "Because the dataframes reside in memory you do not need to specify the location of the data when you create your Data Source. Instead, the type of Data Source you create depends on the type of dataframe containing your data. Great Expectations has methods for connecting to both pandas and Spark dataframes.\n",
    "\n",
    "### Prerequisites\n",
    "[A preconfigured Data Context](https://docs.greatexpectations.io/docs/core/set_up_a_gx_environment/create_a_data_context). These examples assume the variable `context` contains your Data Context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1a427a3-89c2-47ab-8005-1f24c45110fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileDataContext\n"
     ]
    }
   ],
   "source": [
    "# context = gx.get_context() # EphemeralDataContext\n",
    "context = gx.get_context(mode=\"file\") # Let's save the context to the file system\n",
    "print(type(context).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1af6f22-ec93-4ebc-86d0-5ebfab556039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af2ce50a-72af-4015-8e3f-b98e4dae0e6c",
   "metadata": {},
   "source": [
    "### Define the Data Source parameters.\n",
    "\n",
    "A dataframe Data Source requires the following information:\n",
    "\n",
    "- name: A name by which to reference the Data Source. This should be unique among all Data Sources on the Data Context.\n",
    "\n",
    "Update `data_source_name` in the following code with a descriptive name for your Data Source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6340570-ea49-4c76-a718-e7e9b6b5f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source_name = \"my_data_source\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e9401-bb5b-4ea6-b0fe-d5471cdda9a0",
   "metadata": {},
   "source": [
    "### Create the Data Source.\n",
    "\n",
    "To read a pandas dataframe you will need to create a pandas Data Source. Likewise, to read a Spark dataframe you will need to create a Spark Data Source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e8f449b-4240-4067-95da-86e7ebf6ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = context.data_sources.add_pandas(name=data_source_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e7aa63-e8bc-4197-a958-b657dad42b8d",
   "metadata": {},
   "source": [
    "You can see the list of data sources in your context with\n",
    "```\n",
    "context.data_sources.all()\n",
    "```\n",
    "Also, delete one with\n",
    "```\n",
    "context.data_sources.delete(name=data_source_name)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1d6e62-dfca-4a1d-83c4-d5f5b3299522",
   "metadata": {},
   "source": [
    "## Create a Data Asset\n",
    "\n",
    "A dataframe Data Asset is used to group your Validation Results. For instance, if you have a data pipeline with three stages and you wanted the Validation Results for each stage to be grouped together, you would create a Data Asset with a unique name representing each stage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe0fa47-b620-43bd-828a-9d742f4cd580",
   "metadata": {},
   "source": [
    "### Optional. Retrieve your Data Source.\n",
    "\n",
    "If you do not already have a variable referencing your pandas or Spark Data Source, you can retrieve a previously created one with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2bdb488-0b1d-4213-bce8-d5cb675e03fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PandasDatasource(type='pandas', name='my_data_source', id=UUID('68fe3c5e-7dcb-48fa-aa5d-67eb92f6514a'), assets=[])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_source_name = \"my_data_source\"\n",
    "data_source = context.data_sources.get(data_source_name)\n",
    "data_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2af70b-4fcc-4915-8f38-f7c2916aedd3",
   "metadata": {},
   "source": [
    "### Define the Data Asset's parameters.\n",
    "\n",
    "A dataframe Data Asset requires the following information:\n",
    "\n",
    "name: A name by which the Data Asset can be referenced. This should be unique among Data Assets on the Data Source.\n",
    "Update the data_asset_name parameter in the following code with a descriptive name for your Data Asset:\n",
    "\n",
    "Add a Data Asset to the Data Source.\n",
    "\n",
    "Execute the following code to add a Data Asset to your Data Source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64a633f9-9a51-40cc-a39d-34e3c61acd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_asset_name = \"my_dataframe_data_asset\"\n",
    "data_asset = data_source.add_dataframe_asset(name=data_asset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10002e2c-98ed-40e9-9372-a5ff6c635191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35e25f3e-6ad8-4898-8bb4-ee58b16b68cb",
   "metadata": {},
   "source": [
    "## Create a Batch Definition\n",
    "\n",
    "Typically, a Batch Definition is used to describe how the data within a Data Asset should be retrieved. With dataframes, all of the data in a given dataframe will always be retrieved as a Batch.\n",
    "\n",
    "This means that Batch Definitions for dataframe Data Assets don't work to subdivide the data returned for validation. Instead, they serve as an additional layer of organization and allow you to further group your Validation Results. For example, if you have already used your dataframe Data Assets to group your Validation Results by pipeline stage, you could use two Batch Definitions to further group those results by having all automated validations use one Batch Definition and all manually executed validations use the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c59f3b5d-21f6-4722-bbb0-33776132e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_definition_name = \"my_batch_definition\"\n",
    "batch_definition = data_asset.add_batch_definition_whole_dataframe(\n",
    "    batch_definition_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd397d66-4ead-4eed-81b1-eb4b27bdab72",
   "metadata": {},
   "source": [
    "## Provide a dataframe through Batch Parameters\n",
    "Because dataframes exist in memory and cease to exist when a Python session ends the dataframe itself is not saved as part of a Data Assset or Batch Definition. Instead, a dataframe created in the current Python session is passed in at runtime as a Batch Parameter dictionary.\n",
    "\n",
    "Define the Batch Parameter dictionary.\n",
    "\n",
    "A dataframe can be added to a Batch Parameter dictionary by defining it as the value of the dictionary key `dataframe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f28ca0-945b-4b9f-bc25-45f948844b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_parameters = {\"dataframe\": dataframe}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad7fbb95-9b56-40ed-ae6d-6098ac266b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 10,000\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"/data/public/tutorials/ge_tutorials/data/yellow_tripdata_sample_2019-01.csv\"\n",
    "dataframe = pd.read_csv(csv_path)\n",
    "print(f\"Number of records: {dataframe.shape[0]:,}\")\n",
    "batch_parameters = {\"dataframe\": dataframe}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6607d716-933c-42e3-9731-8211bba04544",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_definition = (\n",
    "    context.data_sources.get(data_source_name)\n",
    "    .get_asset(data_asset_name)\n",
    "    .get_batch_definition(batch_definition_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16f3e006-dbcc-46ea-8c5f-167502d686a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Expectation to test\n",
    "expectation = gx.expectations.ExpectColumnValuesToBeBetween(\n",
    "    column=\"passenger_count\", max_value=6, min_value=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81701fbd-736f-4b92-b2c0-16929de733f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataframe as a Batch\n",
    "batch = batch_definition.get_batch(batch_parameters=batch_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b84eb72-77ca-46e2-a09c-034c4ab948cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics: 100%|████████████████████████████████████████████████████| 10/10 [00:00<00:00, 303.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"success\": true,\n",
      "  \"expectation_config\": {\n",
      "    \"type\": \"expect_column_values_to_be_between\",\n",
      "    \"kwargs\": {\n",
      "      \"batch_id\": \"my_data_source-my_dataframe_data_asset\",\n",
      "      \"column\": \"passenger_count\",\n",
      "      \"min_value\": 1.0,\n",
      "      \"max_value\": 6.0\n",
      "    },\n",
      "    \"meta\": {}\n",
      "  },\n",
      "  \"result\": {\n",
      "    \"element_count\": 10000,\n",
      "    \"unexpected_count\": 0,\n",
      "    \"unexpected_percent\": 0.0,\n",
      "    \"partial_unexpected_list\": [],\n",
      "    \"missing_count\": 0,\n",
      "    \"missing_percent\": 0.0,\n",
      "    \"unexpected_percent_total\": 0.0,\n",
      "    \"unexpected_percent_nonmissing\": 0.0,\n",
      "    \"partial_unexpected_counts\": [],\n",
      "    \"partial_unexpected_index_list\": []\n",
      "  },\n",
      "  \"meta\": {},\n",
      "  \"exception_info\": {\n",
      "    \"raised_exception\": false,\n",
      "    \"exception_traceback\": null,\n",
      "    \"exception_message\": null\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the Expectation\n",
    "validation_results = batch.validate(expectation)\n",
    "print(validation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30bcc2c-a30a-4de0-89dc-3ac2d9544d60",
   "metadata": {},
   "source": [
    "# Define Expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778a6044-1836-4912-868e-b75d3cdfcbdf",
   "metadata": {},
   "source": [
    "## Create an Expectation\n",
    "An Expectation is a verifiable assertion about your data. Expectations make implicit assumptions about your data explicit, and they provide a flexible, declarative language for describing expected behavior. They can help you better understand your data and help you improve data quality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0dad0a-be7f-414a-b97a-ca08756c42ef",
   "metadata": {},
   "source": [
    "### Choose an Expectation to create.\n",
    "\n",
    "GX comes with many built in Expectations to cover your data quality needs. You can find a catalog of these Expectations in the Expectation Gallery. When browsing the Expectation Gallery you can filter the available Expectations by the data quality issue they address and by the Data Sources they support. There is also a search bar that will let you filter Expectations by matching text in their name or description.\n",
    "\n",
    "In your code, you will find the classes for Expectations in the expectations module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b484636c-8794-457e-890d-d9c51fb98aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations import expectations as gxe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65667f6a-cb65-4933-afd6-7a41a1e2ca0f",
   "metadata": {},
   "source": [
    "### Determine the Expectation's required parameters\n",
    "\n",
    "To determine the parameters your Expectation uses to evaluate data, reference the Expectation's entry in the Expectation Gallery. Under the Args section you will find a list of parameters that are necessary for the Expectation to be evaluated, along with the a description of the value that should be provided.\n",
    "\n",
    "Parameters that indicate a column, list of columns, or a table must be provided when the Expectation is created. The value in these parameters is used to differentiate instances of the same Expectation class. All other parameters can be set when the Expectation is created or be assigned a dictionary lookup that will allow them to be set at runtime.\n",
    "\n",
    "### Optional. Determine the Expectation's other parameters\n",
    "\n",
    "In addition to the parameters that are required for an Expectation to evaluate data all Expectations also support some standard parameters that determine how strictly Expectations are evaluated and permit the addition of metadata. In the Expectations Gallery these are found under each Expectation's Other Parameters section.\n",
    "\n",
    "These parameters are:\n",
    "\n",
    "| Parameter\t| Purpose |\n",
    "|-----------|---------|\n",
    "| meta\t| A dictionary of user-supplied metadata to store with an Expectation. This dictionary can be used to add notes about the purpose and intended use of an Expectation. |\n",
    "| mostly\t| A special argument that allows for fuzzy validation of ColumnMapExpectations and MultiColumnMapExpectations based on a percentage of successfully validated rows. If the percentage is high enough, the Expectation will return a success value of true. |\n",
    "                                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd21089-b1ab-42d8-9268-c57c2a6a12a9",
   "metadata": {},
   "source": [
    "                                                                                                                               \n",
    "### Create the Expectation.\n",
    "\n",
    "Using the Expectation class you picked and the parameters you determined when referencing the Expectation \n",
    "Gallery, you can create your Expectation.\n",
    "\n",
    "**Preset Parameters**\n",
    "In this example the `ExpectColumnMaxToBeBetween` Expectation is created and all of its parameters are defined in advance while leaving `strict_min` and `strict_max` as their default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9511b829-77ee-4a63-a686-63eda9b7123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preset_expectation = gx.expectations.ExpectColumnMaxToBeBetween(\n",
    "    column=\"passenger_count\", min_value=1, max_value=6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758db1d0-f198-42ee-8f30-cbe7e22d6218",
   "metadata": {},
   "source": [
    "**Runtime Parameters** \n",
    "\n",
    "Runtime parameters are provided by passing a dictionary to the `expectation_parameters` argument of a Checkpoint's `run()` method.\n",
    "\n",
    "To indicate which key in the expectation_parameters dictionary corresponds to a given parameter in an Expectation you define a lookup as the value of the parameter when the Expectation is created. This is done by passing in a dictionary with the key `$PARAMETER` when the Expectation is created. The value associated with the `$PARAMETER` key is the lookup used to find the parameter in the runtime dictionary.\n",
    "\n",
    "In this example, `ExpectColumnMaxToBeBetween` is created for both the passenger_count and the fare fields, and the values for min_value and max_value in each Expectation will be passed in at runtime. To differentiate between the parameters for each Expectation a more specific key is set for finding each parameter in the runtime `expectation_parameters` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed3289a2-f724-4d84-845a-4dfab504f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_expectation = gx.expectations.ExpectColumnMaxToBeBetween(\n",
    "    column=\"passenger_count\",\n",
    "    min_value={\"$PARAMETER\": \"expect_passenger_max_to_be_above\"},\n",
    "    max_value={\"$PARAMETER\": \"expect_passenger_max_to_be_below\"},\n",
    ")\n",
    "fare_expectation = gx.expectations.ExpectColumnMaxToBeBetween(\n",
    "    column=\"fare\",\n",
    "    min_value={\"$PARAMETER\": \"expect_fare_max_to_be_above\"},\n",
    "    max_value={\"$PARAMETER\": \"expect_fare_max_to_be_below\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe63830-893d-4d08-a74c-6568838bbb6d",
   "metadata": {},
   "source": [
    "The runtime expectation_parameters dictionary for the above example would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59078769-d4bf-4f52-a463-8d1ce35ab61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_expectation_parameters = {\n",
    "    \"expect_passenger_max_to_be_above\": 4,\n",
    "    \"expect_passenger_max_to_be_below\": 6,\n",
    "    \"expect_fare_max_to_be_above\": 10.00,\n",
    "    \"expect_fare_max_to_be_below\": 500.00,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f219df2-5ff9-443c-988c-4c8dd7078298",
   "metadata": {},
   "source": [
    "## Retrieve a Batch of sample data\n",
    "Ref: https://docs.greatexpectations.io/docs/core/define_expectations/retrieve_a_batch_of_test_data\n",
    "\n",
    "Expectations can be individually validated against a Batch of data. This allows you to test newly created Expectations, or to create and validate Expectations to further your understanding of new data. But first, you must retrieve a Batch of data to validate your Expectations against.\n",
    "\n",
    "GX provides two methods of retrieving sample data for testing or data exploration. The first is to request a Batch of data from any Batch Definition you have previously configured. The second is to use the built in `pandas_default` Data Source to read in a Batch of data from a datafile such as a .csv or .parquet file without first defining a corresponding Data Source, Data Asset, and Batch Definition.\n",
    "\n",
    "**Batch Definitions** both organize a Data Asset's records into Batches and provide a method for retrieving those records. Any Batch Definition can be used to retrieve a Batch of records for use in testing Expectations or data exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fce54a2f-9d2a-430b-9339-681dd16fecf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/conda-python3.12/lib/python3.12/site-packages/posthog/client.py:310: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = datetime.utcnow().replace(tzinfo=tzutc())\n",
      "/opt/anaconda3/envs/conda-python3.12/lib/python3.12/site-packages/posthog/request.py:26: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  body[\"sentAt\"] = datetime.utcnow().replace(tzinfo=tzutc()).isoformat()\n"
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "\n",
    "context = gx.get_context(mode=\"file\") # set_up_context_for_example(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ba801-5642-4386-add3-9fb9f90e7c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29fa732-4c32-4fbf-bcb9-e0d03bdc34a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the Batch Definition:\n",
    "data_source_name = \"my_data_source\"\n",
    "data_asset_name = \"my_data_asset\"\n",
    "batch_definition_name = \"my_batch_definition\"\n",
    "batch_definition = (\n",
    "    context.data_sources.get(data_source_name)\n",
    "    .get_asset(data_asset_name)\n",
    "    .get_batch_definition(batch_definition_name)\n",
    ")\n",
    "\n",
    "# Retrieve the first valid Batch of data:\n",
    "batch = batch_definition.get_batch()\n",
    "\n",
    "# Or use a Batch Parameter dictionary to specify a Batch to retrieve\n",
    "# These are sample Batch Parameter dictionaries:\n",
    "yearly_batch_parameters = {\"year\": \"2019\"}\n",
    "monthly_batch_parameters = {\"year\": \"2019\", \"month\": \"01\"}\n",
    "daily_batch_parameters = {\"year\": \"2019\", \"month\": \"01\", \"day\": \"01\"}\n",
    "\n",
    "# This code retrieves the Batch from a monthly Batch Definition:\n",
    "\n",
    "batch = batch_definition.get_batch(batch_parameters={\"year\": \"2019\", \"month\": \"01\"})\n",
    "\n",
    "print(batch.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbda170-6122-445f-a93f-be2e13a1ff59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5abbce-e1b4-4053-8e87-8d6c4904550a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ae139b4-03ef-4980-8b7b-7caf1e776e82",
   "metadata": {},
   "source": [
    "The `pandas_default` Data Source is built into every Data Context and can be found at `.data_sources.pandas_default` on your Data Context.\n",
    "\n",
    "The pandas_default Data Source provides methods to read the contents of a single datafile in any format supported by pandas. These `.read_*(...)` methods do not create a Data Asset or Batch Definition for the datafile. Instead, they simply return a Batch of data.\n",
    "\n",
    "Because the pandas_default Data Source's `.read_*(...)` methods only return a Batch and do not save configurations for reading files to the Data Context, they are less versatile than a fully configured Data Source, Data Asset, and Batch Definition. Therefore, the pandas_default Data Source is only intended to facilitate testing Expectations and engaging in data exploration. The pandas_default Data Source's `.read_*(...)` methods are less suited for use in production and automated workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cd19664-d21f-42d6-9ccf-2bc95c0bc0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics: 100%|██████████████████████████████████████████████████████| 1/1 [00:00<00:00, 239.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   vendor_id      pickup_datetime     dropoff_datetime  passenger_count  \\\n",
       "0          1  2019-01-15 03:36:12  2019-01-15 03:42:19                1   \n",
       "1          1  2019-01-25 18:20:32  2019-01-25 18:26:55                1   \n",
       "2          1  2019-01-05 06:47:31  2019-01-05 06:52:19                1   \n",
       "3          1  2019-01-09 15:08:02  2019-01-09 15:20:17                1   \n",
       "4          1  2019-01-25 18:49:51  2019-01-25 18:56:44                1   \n",
       "\n",
       "   trip_distance  rate_code_id store_and_fwd_flag  pickup_location_id  \\\n",
       "0            1.0             1                  N                 230   \n",
       "1            0.8             1                  N                 112   \n",
       "2            1.1             1                  N                 107   \n",
       "3            2.5             1                  N                 143   \n",
       "4            0.8             1                  N                 246   \n",
       "\n",
       "   dropoff_location_id  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                   48             1          6.5    0.5      0.5        1.95   \n",
       "1                  112             1          6.0    1.0      0.5        1.55   \n",
       "2                    4             2          6.0    0.0      0.5        0.00   \n",
       "3                  158             1         11.0    0.0      0.5        3.00   \n",
       "4                   90             1          6.5    1.0      0.5        1.65   \n",
       "\n",
       "   tolls_amount  improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0           0.0                    0.3          9.75                   NaN  \n",
       "1           0.0                    0.3          9.35                   0.0  \n",
       "2           0.0                    0.3          6.80                   NaN  \n",
       "3           0.0                    0.3         14.80                   NaN  \n",
       "4           0.0                    0.3          9.95                   0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "\n",
    "context = gx.get_context()\n",
    "#set_up_context_for_example(context)\n",
    "\n",
    "# Provide the path to a data file:\n",
    "file_path = \"/data/public/tutorials/ge_tutorials/data/yellow_tripdata_sample_2019-01.csv\"\n",
    "\n",
    "# Use the `pandas_default` Data Source to read the file:\n",
    "sample_batch = context.data_sources.pandas_default.read_csv(file_path)\n",
    "\n",
    "# Verify that data was read into `sample_batch`:\n",
    "display(sample_batch.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a047afa-508c-416c-b0e7-9d2cb5df0b43",
   "metadata": {},
   "source": [
    "## Test an Expectation\n",
    "Ref: https://docs.greatexpectations.io/docs/core/define_expectations/test_an_expectation\n",
    "\n",
    "Data can be validated against individual Expectations. This workflow is generally used when engaging in exploration of new data, or when building out a set of Expectations to comprehensively describe the state that your data should conform to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f05ced1d-706d-43f8-aad4-dc923710c695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/conda-python3.12/lib/python3.12/site-packages/posthog/client.py:310: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = datetime.utcnow().replace(tzinfo=tzutc())\n",
      "Calculating Metrics: 100%|██████████████████████████████████████████████████████| 4/4 [00:00<00:00, 402.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"success\": true,\n",
      "  \"expectation_config\": {\n",
      "    \"type\": \"expect_column_max_to_be_between\",\n",
      "    \"kwargs\": {\n",
      "      \"batch_id\": \"default_pandas_datasource-#ephemeral_pandas_asset\",\n",
      "      \"column\": \"passenger_count\",\n",
      "      \"min_value\": 1.0,\n",
      "      \"max_value\": 6.0\n",
      "    },\n",
      "    \"meta\": {}\n",
      "  },\n",
      "  \"result\": {\n",
      "    \"observed_value\": 6\n",
      "  },\n",
      "  \"meta\": {},\n",
      "  \"exception_info\": {\n",
      "    \"raised_exception\": false,\n",
      "    \"exception_traceback\": null,\n",
      "    \"exception_message\": null\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics: 100%|██████████████████████████████████████████████████████| 4/4 [00:00<00:00, 430.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"success\": true,\n",
      "  \"expectation_config\": {\n",
      "    \"type\": \"expect_column_max_to_be_between\",\n",
      "    \"kwargs\": {\n",
      "      \"batch_id\": \"default_pandas_datasource-#ephemeral_pandas_asset\",\n",
      "      \"column\": \"passenger_count\",\n",
      "      \"min_value\": 1.0,\n",
      "      \"max_value\": 6.0\n",
      "    },\n",
      "    \"meta\": {}\n",
      "  },\n",
      "  \"result\": {\n",
      "    \"observed_value\": 6\n",
      "  },\n",
      "  \"meta\": {},\n",
      "  \"exception_info\": {\n",
      "    \"raised_exception\": false,\n",
      "    \"exception_traceback\": null,\n",
      "    \"exception_message\": null\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/anaconda3/envs/conda-python3.12/lib/python3.12/site-packages/posthog/request.py:26: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  body[\"sentAt\"] = datetime.utcnow().replace(tzinfo=tzutc()).isoformat()\n"
     ]
    }
   ],
   "source": [
    "# import great_expectations as gx\n",
    "\n",
    "context = gx.get_context()\n",
    "\n",
    "# Use the `pandas_default` Data Source to retrieve a Batch of sample Data from a data file:\n",
    "file_path = \"/data/public/tutorials/ge_tutorials/data/yellow_tripdata_sample_2019-01.csv\"\n",
    "batch = context.data_sources.pandas_default.read_csv(file_path)\n",
    "\n",
    "# Define the Expectation to test:\n",
    "expectation = gx.expectations.ExpectColumnMaxToBeBetween(\n",
    "    column=\"passenger_count\", min_value=1, max_value=6\n",
    ")\n",
    "\n",
    "# Test the Expectation:\n",
    "validation_results = batch.validate(expectation)\n",
    "\n",
    "# Evaluate the Validation Results:\n",
    "print(validation_results)\n",
    "\n",
    "# If needed, adjust the Expectation's preset parameters and test again:\n",
    "expectation.min_value = 1\n",
    "expectation.max_value = 6\n",
    "\n",
    "# Test the modified expectation and review the new Validation Results:\n",
    "new_validation_results = batch.validate(expectation)\n",
    "print(new_validation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d12fc93-d7ad-47de-8c4e-d7e1f06efa39",
   "metadata": {},
   "source": [
    "# Run Validations\n",
    "\n",
    "## Create a Validation Definition\n",
    "Ref: https://docs.greatexpectations.io/docs/core/run_validations/create_a_validation_definition\n",
    "\n",
    "A Validation Definition is a fixed reference that links a Batch of data to an Expectation Suite. It can be run by itself to validate the referenced data against the associated Expectations for testing or data exploration. Multiple Validation Definitions can also be provided to a Checkpoint which, when run, executes Actions based on the Validation Results for each provided Validation Definition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546b365-de41-4345-b53f-951bc9bc85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "\n",
    "context = gx.get_context()\n",
    "\n",
    "# Retrieve an Expectation Suite\n",
    "expectation_suite_name = \"my_expectation_suite\"\n",
    "expectation_suite = context.suites.get(name=expectation_suite_name)\n",
    "\n",
    "# Retrieve a Batch Definition\n",
    "data_source_name = \"my_data_source\"\n",
    "data_asset_name = \"my_data_asset\"\n",
    "batch_definition_name = \"my_batch_definition\"\n",
    "batch_definition = (\n",
    "    context.data_sources.get(data_source_name)\n",
    "    .get_asset(data_asset_name)\n",
    "    .get_batch_definition(batch_definition_name)\n",
    ")\n",
    "\n",
    "# Create a Validation Definition\n",
    "definition_name = \"my_validation_definition\"\n",
    "validation_definition = gx.ValidationDefinition(\n",
    "    data=batch_definition, suite=expectation_suite, name=definition_name\n",
    ")\n",
    "\n",
    "# Add the Validation Definition to the Data Context\n",
    "validation_definition = context.validation_definitions.add(validation_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20b311-ff72-4f9d-a241-18d1426aab06",
   "metadata": {},
   "source": [
    "## Run a Validation Definition\n",
    "\n",
    "Ref: https://docs.greatexpectations.io/docs/core/run_validations/run_a_validation_definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f488e-e99a-4765-bcae-a9a4480bfaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "\n",
    "context = gx.get_context()\n",
    "\n",
    "# Retrieve the Validation Definition\n",
    "validation_definition_name = \"my_validation_definition\"\n",
    "validation_definition = context.validation_definitions.get(validation_definition_name)\n",
    "\n",
    "# Run the Validation Definition\n",
    "validation_results = validation_definition.run()\n",
    "\n",
    "# Review the Validation Results\n",
    "print(validation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b10152-339d-42d4-97f9-8c511996607a",
   "metadata": {},
   "source": [
    "# Trigger actions based on results\n",
    "\n",
    "## Create a Checkpoint with Actions\n",
    "Ref: https://docs.greatexpectations.io/docs/core/trigger_actions_based_on_results/create_a_checkpoint_with_actions\n",
    "\n",
    "A Checkpoint executes one or more Validation Definitions and then performs a set of Actions based on the Validation Results each Validation Definition returns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0208cc-d4e2-4c3d-a324-cbaa97960265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "\n",
    "context = gx.get_context()\n",
    "set_up_context_for_example(context)\n",
    "\n",
    "# Create a list of one or more Validation Definitions for the Checkpoint to run\n",
    "validation_definitions = [\n",
    "    context.validation_definitions.get(\"my_validation_definition\")\n",
    "]\n",
    "\n",
    "# Create a list of Actions for the Checkpoint to perform\n",
    "action_list = [\n",
    "    # This Action sends a Slack Notification if an Expectation fails.\n",
    "    gx.checkpoint.SlackNotificationAction(\n",
    "        name=\"send_slack_notification_on_failed_expectations\",\n",
    "        slack_token=\"${validation_notification_slack_webhook}\",\n",
    "        slack_channel=\"${validation_notification_slack_channel}\",\n",
    "        notify_on=\"failure\",\n",
    "        show_failed_expectations=True,\n",
    "    ),\n",
    "    # This Action updates the Data Docs static website with the Validation\n",
    "    #   Results after the Checkpoint is run.\n",
    "    gx.checkpoint.UpdateDataDocsAction(\n",
    "        name=\"update_all_data_docs\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Create the Checkpoint\n",
    "checkpoint_name = \"my_checkpoint\"\n",
    "checkpoint = gx.Checkpoint(\n",
    "    name=checkpoint_name,\n",
    "    validation_definitions=validation_definitions,\n",
    "    actions=action_list,\n",
    "    result_format={\"result_format\": \"COMPLETE\"},\n",
    ")\n",
    "\n",
    "# Save the Checkpoint to the Data Context\n",
    "context.checkpoints.add(checkpoint)\n",
    "\n",
    "# Retrieve the Checkpoint later\n",
    "checkpoint_name = \"my_checkpoint\"\n",
    "checkpoint = context.checkpoints.get(checkpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2b6e50-0b39-494f-9381-afb1da159055",
   "metadata": {},
   "source": [
    "## Choose result format\n",
    "\n",
    "Ref: https://docs.greatexpectations.io/docs/core/trigger_actions_based_on_results/choose_a_result_format/\n",
    "\n",
    "When you validate data with GX Core you can set the level of detail returned in your Validation Results by specifying a value for the optional result_format parameter. These settings will be applied to the results returned by each validated Expectation.\n",
    "\n",
    "Typical use cases customizing Result Format settings include summarizing values that cause Expectations to fail durring data exploration, retrieving failed rows to facilitate cleaning data, or excluding excess Validation Result data in published Data Docs.\n",
    "\n",
    "### Create a dictionary and set the verbosity of returned Validation Results.\n",
    "\n",
    "The verbosity of your Validation Results can be set as the value of the key \"result_format\" in your Result Format dictionary. In order from least verbosity to greatest detail, the valid values for the \"result_format\" key are:\n",
    "\n",
    "\"BOOLEAN_ONLY\"\n",
    "\"BASIC\"\n",
    "\"SUMMARY\"\n",
    "\"COMPLETE\".\n",
    "The default verbosity level of Validation Results generated by Expectations is \"SUMMARY\".\n",
    "\n",
    "### Optional. Specify configurations for additional settings available to the base result_format.\n",
    "\n",
    "Once you have defined the base configuration in your result_format key, you can further tailor the format of your Validation Results by defining additional key/value pairs in your Result Format dictionary.\n",
    "\n",
    "Reference the table at https://docs.greatexpectations.io/docs/core/trigger_actions_based_on_results/choose_a_result_format/?result_format_string=basic for valid keys and how they influence the format of generated Validation Results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b4c712-9f26-43dc-a1b1-c294f4eccc66",
   "metadata": {},
   "source": [
    "## Validation Results reference table\n",
    "\n",
    "Ref: https://docs.greatexpectations.io/docs/core/trigger_actions_based_on_results/choose_a_result_format/#validation-results-reference-tables\n",
    "\n",
    "\n",
    "| Field within result\t| Value |\n",
    "|-------------------|------------|\n",
    "|element_count\t|The total number of values in the column.|\n",
    "|missing_count\t|The number of missing values in the column.|\n",
    "|missing_percent\t|The total percent of rows missing values for the column.|\n",
    "|unexpected_count\t|The total count of unexpected values in in a column.|\n",
    "|unexpected_percent\t|The overall percent of unexpected values in a column.|\n",
    "|unexpected_percent_nonmissing\t|The percent of unexpected values in a column, excluding rows that have no value for that column.|\n",
    "|observed_value\t|The aggregate statistic computed for the column. This only applies to Expectations that pertain to the aggregate value |of a column, rather than the individual values in each row for the column.|\n",
    "|partial_unexpected_list\t|A partial list of values that violate the Expectation. (Up to 20 values by default.) |\n",
    "|partial_unexpected_index_list\t|A partial list the unexpected values in the column, as defined by the columns in unexpected_index_column_names. (Up to 20 indecies by default.)|\n",
    "|partial_unexpected_counts\t|A partial list of values and counts, showing the number of times each of the unexpected values occur. (Up to 20 unexpected value/count pairs by default.)|\n",
    "|unexpected_index_list\t|A list of the indices of the unexpected values in the column, as defined by the columns in unexpected_index_column_names.|\n",
    "|unexpected_index_query\t|A query that can be used to retrieve all unexpected values (SQL and Spark), or the full list of unexpected indices (Pandas).|\n",
    "|unexpected_list\t|A list of up to 200 values that violate the Expectation.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983e6b49-c1a5-4dc1-8890-d75a228ce5aa",
   "metadata": {},
   "source": [
    "## Run a Checkpoint\n",
    "Ref: https://docs.greatexpectations.io/docs/core/trigger_actions_based_on_results/run_a_checkpoint\n",
    "\n",
    "Running a Checkpoint will cause it to validate all of its Validation Definitions. It will then execute its Actions based on the results returned from those Validation Definitions. Finally, the Validation Results will be returned by the Checkpoint.\n",
    "\n",
    "At runtime, a Checkpoint can take in a batch_parameters dictionary that selects the Batch to validate from each Validation Definition. A Checkpoint will also accept an expectation_parameters dictionary that provides values for the parameters of the any Expectations that have been configured to accept parameters at runtime.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a7f1f-4d76-4cee-a64c-8df69f0ca5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "\n",
    "context = gx.get_context()\n",
    "set_up_context_for_example(context)\n",
    "\n",
    "checkpoint = context.checkpoints.get(\"my_checkpoint\")\n",
    "\n",
    "batch_parameters = {\"month\": \"01\", \"year\": \"2019\"}\n",
    "\n",
    "expectation_parameters = {\n",
    "    \"expect_fare_max_to_be_above\": 5.00,\n",
    "    \"expect_fare_max_to_be_below\": 1000.00,\n",
    "}\n",
    "\n",
    "validation_results = checkpoint.run(\n",
    "    batch_parameters=batch_parameters, expectation_parameters=expectation_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086751f4-01c4-413f-840f-1572550d0dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1d3a07-56c6-493d-9d0a-928c3fb2d7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9193bcf1-d776-4993-8da3-da21d502d348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a127a55-6851-4187-8ab3-fe3a8777eb7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda Python 3.12",
   "language": "python",
   "name": "conda-python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
